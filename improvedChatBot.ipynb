{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce2c27c-03f9-4cc3-802d-e7e6ce916cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   query  \\\n",
      "0     \"How do I sign up for an account?\"   \n",
      "1       \"How do I log in to my account?\"   \n",
      "2          \"How do I reset my password?\"   \n",
      "3          \"How do I delete my account?\"   \n",
      "4  \"How do I change my account details?\"   \n",
      "\n",
      "                                            response  \n",
      "0  \"To sign up, click the 'Sign Up' button on the...  \n",
      "1  \"To log in, click the 'Login' button, enter yo...  \n",
      "2  \"To reset your password, go to the login page ...  \n",
      "3  \"To delete your account, navigate to your acco...  \n",
      "4  \"Go to your profile settings and click on 'Edi...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv(\"improving.csv\")\n",
    "\n",
    "# Check the dataset structure\n",
    "print(dataset.head())\n",
    "\n",
    "# Ensure the dataset has clear columns 'query' and 'response'\n",
    "if \"query\" not in dataset.columns or \"response\" not in dataset.columns:\n",
    "    raise ValueError(\"The dataset must contain 'query' and 'response' columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bed0cbc-7fb3-4aa8-9992-b730d3c3b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b19a98670447eaa518ac6a24ce1512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '\"How do I sign up for an account?\"', 'response': '\"To sign up, click the \\'Sign Up\\' button on the homepage, fill out the required information, and confirm your email.\"', 'text': '<|query|> \"How do I sign up for an account?\" <|response|> \"To sign up, click the \\'Sign Up\\' button on the homepage, fill out the required information, and confirm your email.\"'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Prepare the dataset by concatenating query and response with markers\n",
    "def add_markers(examples):\n",
    "    examples['text'] = f\"<|query|> {examples['query']} <|response|> {examples['response']}\"\n",
    "    return examples\n",
    "\n",
    "# Convert pandas DataFrame to HuggingFace Dataset\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "dataset = dataset.map(add_markers)\n",
    "\n",
    "# Print example with markers\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb175bf3-f44c-4461-a917-a066f0eb6e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91d86d3b5e9430a9e73f65e35ec0e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec589e271e244b01ada3b8b4b3ec6c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 36:26, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.426800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.070100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=0.3366526330510775, metrics={'train_runtime': 2216.7917, 'train_samples_per_second': 0.686, 'train_steps_per_second': 0.054, 'total_flos': 99290972160000.0, 'train_loss': 0.3366526330510775, 'epoch': 40.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "\n",
    "# Initialize the GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', clean_up_tokenization_spaces=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set EOS token as pad token\n",
    "\n",
    "# Tokenize function to handle input formatting\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set input_ids as labels for language modeling task\n",
    "def prepare_data_for_gpt2(examples):\n",
    "    import torch\n",
    "\n",
    "    # Convert input_ids to tensors if they are not already\n",
    "    input_ids = torch.tensor(examples['input_ids']) if not isinstance(examples['input_ids'], torch.Tensor) else examples['input_ids']\n",
    "    \n",
    "    # Clone input_ids to create labels\n",
    "    examples['labels'] = input_ids.clone()\n",
    "    return examples\n",
    "\n",
    "\n",
    "# Apply the preparation\n",
    "final_dataset = tokenized_dataset.map(prepare_data_for_gpt2)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=40,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=final_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b271538-0326-4e0c-85fd-d026c56fb23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response: How do i receive notifications?\n",
      "\n",
      "To receive notifications, go to the 'Settings' tab and toggle on 'Notifications'. Follow the prompts to update your account details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    input_text = \"How do i receive notifications?\"\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate response from the fine-tuned model\n",
    "    output = model.generate(\n",
    "        inputs['input_ids'], \n",
    "        attention_mask=inputs['attention_mask'], \n",
    "        max_length=150,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample= True,\n",
    "        temperature=0.7,  # Adjust for more creativity vs. determinism\n",
    "        top_k=50,         # Consider top k most likely next words\n",
    "        top_p=0.9,  \n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "\n",
    "    # Decode and print the response\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "   \n",
    "    print(f\"Chatbot response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c78ca2f5-870c-46e5-b416-90efb02e94a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "697a9f47-891f-49f8-9e8d-782d064ab390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/Users/DELL/Desktop/test/chatBot_and_tokenizer\\\\tokenizer_config.json',\n",
       " 'C:/Users/DELL/Desktop/test/chatBot_and_tokenizer\\\\special_tokens_map.json',\n",
       " 'C:/Users/DELL/Desktop/test/chatBot_and_tokenizer\\\\vocab.json',\n",
       " 'C:/Users/DELL/Desktop/test/chatBot_and_tokenizer\\\\merges.txt',\n",
       " 'C:/Users/DELL/Desktop/test/chatBot_and_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory where you want to save the model and tokenizer\n",
    "save_directory = \"C:/Users/DELL/Desktop/test/chatBot_and_tokenizer\"\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9dfcbf-7466-47b0-989a-4103aaf09679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
